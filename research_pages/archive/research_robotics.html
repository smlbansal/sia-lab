<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Somil Bansal</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />


		<script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		  ga('create', 'UA-78683315-1', 'auto');
		  ga('send', 'pageview');

		</script>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Learning and Intelligent Robotics</strong></a>
								</header>

							<!-- Content -->
							<!-- Content -->
							<section>
								<!-- Content -->
								<p> 
									Machine learning presents a promising approach to develop robots that operate intelligently in new settings using their (past), especially due to its ability to elegantly process rich sensory inputs (e.g., vision). However, the modern learning-based systems remain notoriously data hungry and tend to have non-robust behaviors outside their training regime. In this research thrust, we focus on developing integrated approaches that use classical model-based methods as inductive bias within the learning process for improving the generalization and data efficiency of learned controllers.
								</p>

								<h2 id="content"> Combining Optimal Control and Learning for Visual Navigation in Novel Environments</h2>
								<div id="banner" class="content">
									<div class="image26 object">
										<img src="images/research_images/visnav2.gif" style="height: 225px; width: auto" alt="">
									</div>
									<span class="content">
										<p>
											Real-world autonomous vehicles often need to navigate in a priori unknown environments. In this work, we propose a modular approach that enables autonomous navigation in unknown enviornments using only the monocular RGB images from an onboard camera. Our approach uses machine learning for high-level planning based on perceptual information; this high-level plan is then used for low-level planning and control via leveraging classical model-based, control-theoretic approaches. This modular policy leads to a significantly better performance in new, unseen buildings compared to pure learning- based approaches. In addition, we demonstrate that a navigation policy encapsulated in this fashion can be transferred from simulation to reality directly with no retraining or finetuning, demonstrating the robust generalization capabilities of the learned policy. Finally, a side advantage of our integrated policy is its significant data efficiency compared to pure learning-based approaches (a 10x improvement in sample complexity!).
										</p>
										<a href="https://arxiv.org/pdf/1903.02531.pdf">[Paper]</a> <a href="https://smlbansal.github.io/LB-WayPtNav/">[Project Website]</a><a href="https://youtu.be/7nC19Ai9u5E">[Video]</a>
									</span>
								</div> 

								<h2 id="content"> Visual Navigation Among Humans With Optimal Control as a Supervisor</h2>
								<div id="banner" class="content">
									<div class="image26 object">
										<img src="images/research_images/humanav.gif" style="height: 225px; width: auto" alt="">
									</div>
									<span class="content">
										<p>
											Autonomous robots often navigate in unfamiliar, dynamic environments, where they need to share the space with humans. Navigating around humans is especially difficult because it requires predicting their future motion, which can be quite challenging. We propose a novel framework for navigation around humans which combines learning-based perception with model-based optimal control. The proposed framework learns to anticipate and react to peoples' motion based only on a monocular RGB image, without explicitly predicting the future human motion. Our method generalizes well to unseen buildings and humans in both simulation and real world environments. Furthermore, our experiments demonstrate that combining model-based control and learning leads to better and more data-efficient navigational behaviors as compared to a purely learning based approach.
										</p>
										<a href="https://arxiv.org/pdf/2003.09354.pdf">[Paper]</a> <a href="https://smlbansal.github.io/LB-WayPtNav-DH/">[Project Website]</a><a href="https://github.com/vtolani95/HumANav-Release">[Code]</a>
									</span>
								</div> 

								<h2 id="content"> Goal-Driven Dynamics Learning via Bayesian Optimization </h2>
								<div id="banner" class="content">
									<div class="image26 object">
										<img src="images/research_images/Crazyflie_v2.png" style="height: 200px; width: auto" alt="">
									</div>
									<span class="content">
										<p>
											Autonomous systems will inevitably experience external effects in unstructured environments, which are often hard to model using first principles. In this work, we develop a data-driven framework to learn a model of external effects that are specific to the control task at hand. This does not necessarily lead to learning the most accurate dynamics model; instead, it identifies a “coarse and local” model that can be learned with a small amount of data, and yet yields the best closed-loop controller performance when provided to the optimal control method used.
										</p>
										<a href="https://arxiv.org/pdf/1703.09260.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=Too_GmSzOAA">[Video]</a>
									</span>
								</div> 

								<h2>For a more exhaustive list of our research work please go <a href="publications.html"><u>HERE!</u></a>  </h2> 
							</section>
						</div>
					</div>

													<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>SIA Lab</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li><a href="research.html">Research</a></li>
										<li><a href="people.html">People</a></li>
										<li><a href="teaching.html">Teaching</a></li>
										<li><a href="tutorial.html">Tutorials and Workshops</a></li>
										<!-- <li>
											<span class="opener">Outreach</span>
											<ul>
												<li><a href="tutorial.html">Tutorials and Workshops</a></li>
												<li><a href="ug_and_g.html">UG and Graduate</a></li>
												<li><a href="k12.html">K-12</a></li>
											</ul>
										</li> -->
										<li><a href="publications.html">Publications</a></li>
										<li><a href="talks.html">Talks</a></li>
										<li><a href="joinus.html">Join Us!</a></li>
									</ul>
								</nav>

						</div>
					</div>
            
                        </div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>